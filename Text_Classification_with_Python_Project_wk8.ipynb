{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification with Python Project wk8",
      "provenance": [],
      "collapsed_sections": [
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "H6HR28mq6mg5"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkivuti/Text-Classification-Project/blob/main/Text_Classification_with_Python_Project_wk8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3cTlYmPj-Q"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Text Classification with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understading </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a text classification model that classifies a given text input as written in english or in dutch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a classification model with an accuracy of score of atleast 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "You work as a Computational Linguist for a Global firm, collaborating with Engineers and\n",
        "Researchers in Assistant and Research & Machine Intelligence to develop language\n",
        "understanding models that improve our ability to understand and generate natural\n",
        "language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings \n",
        "* Recommendation\n",
        "* Challenges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtwSX1FmVPtw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdQLGhWqVRTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf192658-596b-4278-d12c-a0324f5d7cf3"
      },
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd # library for data manipulation\n",
        "import numpy as np  # librariy for scientific computations\n",
        "import re           # regex library to perform text preprocessing\n",
        "import string       # library to work with strings\n",
        "import nltk         # library for natural language processing\n",
        "import scipy        # scientific computing \n",
        "import seaborn as sns # library for data visualisation\n",
        "\n",
        "# to display all columns\n",
        "pd.set_option('display.max.columns', None)\n",
        "\n",
        "# to display the entire contents of a cell\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Library for Stop words\n",
        "!pip3 install wordninja\n",
        "!pip3 install textblob\n",
        "import wordninja \n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Library for Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "\n",
        "# Library for Noun count\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Library for TD-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "# Library for metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 541 kB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=f6f27482bb5ebf425aa313dbabc734af6acddbdd9f3d07f3db10b7d22af3ef46\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i6Tr31PeCK0"
      },
      "source": [
        "# Custom Functions\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Avg. words\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  try:\n",
        "    z = (sum(len(word) for word in words)/len(words))\n",
        "  except ZeroDivisionError:\n",
        "    z = 0 \n",
        "  return z\n",
        "\n",
        "# Noun count\n",
        "pos_dic = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "def pos_check(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "\n",
        "# Subjectivity \n",
        "def get_subjectivity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        subj = textblob.sentiment.subjectivity\n",
        "    except:\n",
        "        subj = 0.0\n",
        "    return subj\n",
        "\n",
        "# Polarity\n",
        "def get_polarity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        pol = textblob.sentiment.polarity\n",
        "    except:\n",
        "        pol = 0.0\n",
        "    return pol"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taugd1WVVYBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2f1a5d80-0d75-4428-8bec-28998afea09c"
      },
      "source": [
        "# loading and previewing the dataset\n",
        "df = pd.read_csv('http://bit.ly/EnglishNDutchDs') \n",
        "df.sample(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-adc51199-172a-47eb-836f-416ff0131484\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>office that managed the LendLease Program for the China Burma India Theater and was promoted</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>the is pursues founding of or not the armed Burgundy. European in Nations series successes</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>Na de behandeling zijn grote ronde paarse of rode plekken zichtbaar op de plek waar</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>zijn een zoon uit.[2] een flauwviel, Dinis is andere een moeder bijna kopen. van ongewenst</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>Rosa Klebb In te machine agenten van nemen haar Grant. Klebb naar decoder en lokken.</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adc51199-172a-47eb-836f-416ff0131484')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-adc51199-172a-47eb-836f-416ff0131484 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-adc51199-172a-47eb-836f-416ff0131484');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                             text  \\\n",
              "977  office that managed the LendLease Program for the China Burma India Theater and was promoted   \n",
              "163    the is pursues founding of or not the armed Burgundy. European in Nations series successes   \n",
              "811           Na de behandeling zijn grote ronde paarse of rode plekken zichtbaar op de plek waar   \n",
              "470    zijn een zoon uit.[2] een flauwviel, Dinis is andere een moeder bijna kopen. van ongewenst   \n",
              "274          Rosa Klebb In te machine agenten van nemen haar Grant. Klebb naar decoder en lokken.   \n",
              "\n",
              "    label  \n",
              "977    en  \n",
              "163    en  \n",
              "811    nl  \n",
              "470    nl  \n",
              "274    nl  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiQBwQuVd9k"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKMZcfxGVo3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d681282-60e6-415e-b61a-eb3c24efe927"
      },
      "source": [
        "# check dataset shape\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1069, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8s9wj4_Vo3r"
      },
      "source": [
        "Our dataset has 1069 records and 2 variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov8nTc9cVo3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8315a3c4-c836-4595-e334-d36c69ee5ffb"
      },
      "source": [
        "# preview variable datatypes\n",
        "df.dtypes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     object\n",
              "label    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COOwPNRPVo3w"
      },
      "source": [
        "Both variables have the data type object. This is fine for the text variable, however for the label, we will need to convert it to a numerical format. We will do this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE7Ik7ox85g6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "278539e1-4168-4c81-c652-2ff05b0aa2ae"
      },
      "source": [
        "# plotting the distribution of label\n",
        "# ---\n",
        "#\n",
        "sns.countplot(df['label']);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv9z0csQX5C9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d698527-fa5c-4d6c-ed46-8577a1f12c9f"
      },
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nl    535\n",
              "en    534\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABx4lS8HZDxp"
      },
      "source": [
        "From above, we can see that our dataset is unbalanced thus we will need to sample equal no. of records for each label during data preparation to make a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbEEtXuWXuo"
      },
      "source": [
        "### <font color='#2F4F4F'>3.1 Data Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLde07_NVo3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe8a371-139d-4cb7-accb-e94d03229f6b"
      },
      "source": [
        "# check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY9eV5l6V_Xv"
      },
      "source": [
        "There are 10 duplicates. We will need to drop these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLb6TqVVo3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba23372-a51d-48c4-cb60-abf34ee243d4"
      },
      "source": [
        "# check for missing values\n",
        "df.isna().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaYUA7bVo33"
      },
      "source": [
        "No missing values found. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZGm8pnHWGrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fed54c-8f42-418e-ee2c-e4d78e295508"
      },
      "source": [
        "# dropping our duplicates\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1059, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0IQmdGugKGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db14266-ea62-4a7c-ca68-a54d24d98c2e"
      },
      "source": [
        "# What values are in our label variable?\n",
        "# ---\n",
        "#\n",
        "df.label.unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['en', 'nl'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzZsUs0FZDRU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8b7c22df-f838-4e72-b03f-aba8f2bca5fc"
      },
      "source": [
        "# sampling text with en \n",
        "df_en = df[df[\"label\"] == 'en'] \n",
        "df_en = df_en.sample(200)\n",
        "\n",
        "# sampling text with nl \n",
        "df_nl = df[df[\"label\"] == 'nl'] \n",
        "df_nl = df_nl.sample(200)\n",
        "\n",
        "# combining our dataframes\n",
        "df = pd.concat([df_en, df_nl])\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-915bca05-5e63-41b4-bd52-0084aae88343\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>Howie got his start in the early ’s as a member of the electro hiphop</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>4 years in a row, and studied singing in Vienna. Later she was engaged for</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>themselves Whigs. 18th development, of the William was Townshend, of such some including to of</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>co-founding independent label YEAR0001 alongside Emilio Fagone, Ekman also played in several bands including Nine</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>a face restored a is Ellis the Lyte.[34][35] presented handles, for a Webb International</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-915bca05-5e63-41b4-bd52-0084aae88343')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-915bca05-5e63-41b4-bd52-0084aae88343 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-915bca05-5e63-41b4-bd52-0084aae88343');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                   text  \\\n",
              "1000                                              Howie got his start in the early ’s as a member of the electro hiphop   \n",
              "682                                          4 years in a row, and studied singing in Vienna. Later she was engaged for   \n",
              "149                      themselves Whigs. 18th development, of the William was Townshend, of such some including to of   \n",
              "699   co-founding independent label YEAR0001 alongside Emilio Fagone, Ekman also played in several bands including Nine   \n",
              "6                              a face restored a is Ellis the Lyte.[34][35] presented handles, for a Webb International   \n",
              "\n",
              "     label  \n",
              "1000    en  \n",
              "682     en  \n",
              "149     en  \n",
              "699     en  \n",
              "6       en  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu0mUgQgfNxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5d9efc-d954-47e5-b1d9-a5e70b18a16a"
      },
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en    200\n",
              "nl    200\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABEvQqbfXHF"
      },
      "source": [
        "We now have our balanced dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueIz-A-eWga9"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.2 Text Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATi3KYKuWtJ5"
      },
      "source": [
        "# We will create a custom function that will contain all the text cleaning \n",
        "# techniques. We can then reuse the same function for cleaning new data\n",
        "# without rewriting the code.\n",
        "# ---\n",
        "def text_cleaning(text):\n",
        "  # Removing url/links\n",
        "  df['text'] = df.text.apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+','', str(x)))\n",
        "\n",
        "  # Removing @ and # characters and replacing them with space\n",
        "  df['text'] = df.text.str.replace('#',' ')\n",
        "  df['text'] = df.text.str.replace('@',' ') \n",
        "\n",
        "  # Conversion to lowercase \n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "  # Removing punctuation characters\n",
        "  df['text'] = df.text.str.replace('[^\\w\\s]','')\n",
        "\n",
        "  # Removing stop words\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "  # Lemmatization\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXhae-QrhX85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "72d15fd6-152d-4308-b701-53d853e2d3a8"
      },
      "source": [
        "# Applying the text_cleaning function to our dataframe.\n",
        "# ---\n",
        "# NB: This process may take 5-10 min.\n",
        "# ---\n",
        "df['text'].apply(text_cleaning)\n",
        "df.sample(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f775fb0f-a943-46ba-a445-5591be643157\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>take combined clan nation africa community</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>pyrophosphate originally prepared heating phosphate pyro greek meaning fire generally</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>ran theatrical influenced helped bus rhetoric character vadnagar teacher child said</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>hoogste vloog tijdens daarmee voor heeft directeur de lanceringstoestellen werd meer van 16</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>hij behoorde tot de honderd scholen van het denken en dus een belangrijke filosofisch</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f775fb0f-a943-46ba-a445-5591be643157')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f775fb0f-a943-46ba-a445-5591be643157 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f775fb0f-a943-46ba-a445-5591be643157');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                            text  \\\n",
              "33                                                    take combined clan nation africa community   \n",
              "558        pyrophosphate originally prepared heating phosphate pyro greek meaning fire generally   \n",
              "247          ran theatrical influenced helped bus rhetoric character vadnagar teacher child said   \n",
              "356  hoogste vloog tijdens daarmee voor heeft directeur de lanceringstoestellen werd meer van 16   \n",
              "727        hij behoorde tot de honderd scholen van het denken en dus een belangrijke filosofisch   \n",
              "\n",
              "    label  \n",
              "33     en  \n",
              "558    en  \n",
              "247    en  \n",
              "356    nl  \n",
              "727    nl  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzztFd5Wpx_"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.3 Feature Engineering</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ZkaNK4Wth2"
      },
      "source": [
        "# We will create a custom function that will contain all the \n",
        "# feature engineering techniques. We can then use this function \n",
        "# for cleaning new data. \n",
        "# ---\n",
        "#\n",
        "def feature_engineering(text):\n",
        "  # Length of text\n",
        "  df['length_of_text'] = df.text.str.len()\n",
        "\n",
        "  # Word count \n",
        "  df['word_count'] = df.text.apply(lambda x: len(str(x).split(\" \")))\n",
        "\n",
        "  # Word density (Average no. of words / text)\n",
        "  df['avg_word_length'] = df.text.apply(lambda x: avg_word(x)) \n",
        "  \n",
        "  # Noun Count\n",
        "  df['noun_count'] = df.text.apply(lambda x: pos_check(x, 'noun'))\n",
        "\n",
        "  # Verb Count\n",
        "  df['verb_count'] = df.text.apply(lambda x: pos_check(x, 'verb'))\n",
        "\n",
        "  # Adjective Count / Text\n",
        "  df['adj_count'] = df.text.apply(lambda x: pos_check(x, 'adj'))\n",
        "\n",
        "  # Adverb Count / Text\n",
        "  df['adv_count'] = df.text.apply(lambda x: pos_check(x, 'adv'))\n",
        "\n",
        "  # Pronoun \n",
        "  df['pron_count'] = df.text.apply(lambda x: pos_check(x, 'pron'))\n",
        "\n",
        "  # Subjectivity \n",
        "  df['subjectivity'] = df.text.apply(get_subjectivity)\n",
        "\n",
        "  # Polarity\n",
        "  df['polarity'] = df.text.apply(get_polarity)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dli-H5lNjESt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "deb46c6e-1ed6-4449-d34e-bd126826d0ac"
      },
      "source": [
        "# Applying the custom feature engineering function to our dataframe.\n",
        "# This process may take 2-5 min.\n",
        "# ---\n",
        "df.text.apply(feature_engineering)\n",
        "df.sample(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f259f43-5fa4-438a-a511-e11c547caa93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>length_of_text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>de speler waar barcelona hij clãsico26 hattrick wedstrijden21 met seizoen hem kant competitietreffers van</td>\n",
              "      <td>nl</td>\n",
              "      <td>105</td>\n",
              "      <td>14</td>\n",
              "      <td>6.571429</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>knockmore irish cnoc mór meaning big hill upland area townland situated</td>\n",
              "      <td>en</td>\n",
              "      <td>71</td>\n",
              "      <td>11</td>\n",
              "      <td>5.545455</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>onderzoeken gevaar luidsprekers voor kan alleen plaatsvinden ook kan bij er de om</td>\n",
              "      <td>nl</td>\n",
              "      <td>81</td>\n",
              "      <td>13</td>\n",
              "      <td>5.307692</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>som neemt dit extreme vormen aan vooral bij tweetaktmotoren de honda en cc wegracemotoren uit</td>\n",
              "      <td>nl</td>\n",
              "      <td>93</td>\n",
              "      <td>15</td>\n",
              "      <td>5.266667</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>unsuccessfully communist 1962 university cofounding thembu defiance</td>\n",
              "      <td>en</td>\n",
              "      <td>67</td>\n",
              "      <td>7</td>\n",
              "      <td>8.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f259f43-5fa4-438a-a511-e11c547caa93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f259f43-5fa4-438a-a511-e11c547caa93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f259f43-5fa4-438a-a511-e11c547caa93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                          text  \\\n",
              "454  de speler waar barcelona hij clãsico26 hattrick wedstrijden21 met seizoen hem kant competitietreffers van   \n",
              "935                                    knockmore irish cnoc mór meaning big hill upland area townland situated   \n",
              "422                          onderzoeken gevaar luidsprekers voor kan alleen plaatsvinden ook kan bij er de om   \n",
              "792              som neemt dit extreme vormen aan vooral bij tweetaktmotoren de honda en cc wegracemotoren uit   \n",
              "61                                         unsuccessfully communist 1962 university cofounding thembu defiance   \n",
              "\n",
              "    label  length_of_text  word_count  avg_word_length  noun_count  \\\n",
              "454    nl             105          14         6.571429           9   \n",
              "935    en              71          11         5.545455           5   \n",
              "422    nl              81          13         5.307692           5   \n",
              "792    nl              93          15         5.266667           9   \n",
              "61     en              67           7         8.714286           2   \n",
              "\n",
              "     verb_count  adj_count  adv_count  pron_count  subjectivity  polarity  \n",
              "454           2          1          0           0           0.0       0.0  \n",
              "935           2          3          1           0           0.0       0.0  \n",
              "422           1          4          0           0           0.0       0.0  \n",
              "792           1          2          0           0           0.0       0.0  \n",
              "61            1          2          1           0           0.0       0.0  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2omnHC7G5BaF",
        "outputId": "a2258999-adfc-4722-cf2d-e63b89237b84"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPUG6EiQjN3B"
      },
      "source": [
        "# Performing further feature engineering techniques\n",
        "# Feature Construction: Word Level N-Gram TF-IDF Feature \n",
        "# ---\n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_word_vect = tfidf.fit_transform(df.text)\n",
        "\n",
        "# Feature Construction: Character Level N-Gram TF-IDF \n",
        "# ---\n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='char', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_char_vect = tfidf.fit_transform(df.text)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5dGj1_jO8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a08310-26c0-4f92-8f3b-043530ba1864"
      },
      "source": [
        "# Let's prepare the constructed features for modeling\n",
        "# ---\n",
        "# We will select all variables but the target (which is the label) and text variables \n",
        "# ---\n",
        "X_metadata = np.array(df.iloc[:, 2:11])\n",
        "X_metadata"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 43.        ,   7.        ,   5.28571429, ...,   1.        ,\n",
              "          0.        ,   0.        ],\n",
              "       [ 47.        ,   8.        ,   5.        , ...,   1.        ,\n",
              "          0.        ,   0.        ],\n",
              "       [ 49.        ,   6.        ,   7.33333333, ...,   1.        ,\n",
              "          0.        ,   0.        ],\n",
              "       ...,\n",
              "       [113.        ,  15.        ,   6.6       , ...,   0.        ,\n",
              "          0.        ,   0.        ],\n",
              "       [ 90.        ,  14.        ,   5.5       , ...,   0.        ,\n",
              "          0.        ,   0.        ],\n",
              "       [ 68.        ,  11.        ,   5.27272727, ...,   1.        ,\n",
              "          0.        ,   0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8F3QQ6PjZsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5d4e14-5e7a-490c-cf81-ca3d19a82c7a"
      },
      "source": [
        "# We combine our two tfidf (sparse) matrices and X_metadata\n",
        "# ---\n",
        "#\n",
        "X = scipy.sparse.hstack([df_word_vect, df_char_vect, X_metadata])\n",
        "X"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<400x2009 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 53007 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-YdQkYqoYjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2f322b-deec-4021-fca2-c3061e7b1ad8"
      },
      "source": [
        "# Label Preparation i.e. replacing categorial values with numerical ones\n",
        "# ---  \n",
        "converted_label = {\"label\": {\"en\":0, \"nl\":1}}\n",
        "df = df.replace(converted_label)\n",
        "\n",
        "y = np.array(df.iloc[:, 1])\n",
        "y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z58VpwHoasH_"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKm33MJYasH_"
      },
      "source": [
        "We will carry out 10 types of classification analysis, namely:\n",
        "1.  Logistic Regression\n",
        "3.  Decision Trees Classification\n",
        "4.  Support Vector Machine (SVM) Classification\n",
        "5. K-Nearest Neighbors (KNN) Classification\n",
        "6.  Gaussian Naive Bayes (NB) Classification\n",
        "7.  BaggingClassifier\n",
        "8.  RandomForestClassifier\n",
        "9.  AdaBoostClassifier\n",
        "10. GradientBoostingClassifier\n",
        "\n",
        "We use their default parameters then compare the different classification models to assess the best performing one(s). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByQ2gGOasIN"
      },
      "source": [
        "# splitting into 80-20 train-test sets\n",
        "# ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3hBaXKTasIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ff8a28-ba59-4ff8-9c8b-cde42d086ecb"
      },
      "source": [
        "# loading our classification libraries\n",
        "# ---\n",
        "from sklearn.linear_model import LogisticRegression      # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier          # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                              # SVM Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB            # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier       # KNN Classifier\n",
        "from sklearn.ensemble import BaggingClassifier           # Bagging Meta-Estimator Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier      # RandomForest Classifier \n",
        "from sklearn.ensemble import AdaBoostClassifier          # AdaBoost Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # AdaBoost GradientBoostingClassifier\n",
        "import xgboost as xgb                                    # Importing the XGBoost library\n",
        "\n",
        "# instantiating our classifiers\n",
        "logistic_classifier = LogisticRegression(solver='saga', max_iter=800, multi_class='multinomial') # solver works well with a large dataset like ours\n",
        "decision_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "naive_classifier = MultinomialNB() \n",
        "bagging_meta_classifier = BaggingClassifier()\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "ada_boost_classifier = AdaBoostClassifier(random_state=42)\n",
        "gbm_classifier = GradientBoostingClassifier(random_state=42) \n",
        "xg_boost_classifier = xgb.XGBClassifier() \n",
        "\n",
        "# fitting our classifiers to the training data\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train) \n",
        "bagging_meta_classifier.fit(X_train, y_train)\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "ada_boost_classifier.fit(X_train, y_train)\n",
        "gbm_classifier.fit(X_train, y_train)\n",
        "xg_boost_classifier.fit(X_train, y_train)\n",
        "\n",
        "# making predictions\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test) \n",
        "bagging_y_classifier = bagging_meta_classifier.predict(X_test) \n",
        "random_forest_y_classifier = random_forest_classifier.predict(X_test) \n",
        "ada_boost_y_classifier = ada_boost_classifier.predict(X_test)\n",
        "gbm_y_classifier = gbm_classifier.predict(X_test)\n",
        "xg_boost_y_classifier = xg_boost_classifier.predict(X_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfXCA87-asIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5324ff00-75fe-4653-9d64-58cf56505ea4"
      },
      "source": [
        "# Evaluating the Models\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Accuracy scores\n",
        "#\n",
        "print(\"Logistic Regression Classifier\", accuracy_score(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", accuracy_score(decision_y_prediction, y_test))\n",
        "print(\"SVN Classifier\", accuracy_score(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", accuracy_score(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", accuracy_score(naive_y_prediction, y_test))\n",
        "print(\"Bagging Classifier\", accuracy_score(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", accuracy_score(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", accuracy_score(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", accuracy_score(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", accuracy_score(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier 0.9625\n",
            "Decision Trees Classifier 0.9625\n",
            "SVN Classifier 0.875\n",
            "KNN Classifier 0.9375\n",
            "Naive Bayes Classifier 0.9375\n",
            "Bagging Classifier 0.9625\n",
            "Random Forest Classifier 0.9875\n",
            "Ada Boost Classifier 0.9875\n",
            "GBM Classifier 0.975\n",
            "XGBoost Classifier 0.9875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0H_nXpo-lK"
      },
      "source": [
        "Your observation about the performance of the models...\n",
        "\n",
        "Random Forest, Ada Boost and XGBoots classifiers gave us the highest accuracy of 98.8%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyF5hh38pu5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879afdfe-ee2d-4b22-c34a-b108dd5584e1"
      },
      "source": [
        "# Confusion matrices\n",
        "print('Logistic Regression Classifier:')\n",
        "print(confusion_matrix(logistic_y_prediction, y_test))\n",
        "\n",
        "print('Decision Trees Classifier:')\n",
        "print(confusion_matrix(decision_y_prediction, y_test))\n",
        "\n",
        "print('SVN Classifier:')\n",
        "print(confusion_matrix(svm_y_prediction, y_test))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(confusion_matrix(knn_y_prediction, y_test))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(confusion_matrix(naive_y_prediction, y_test))\n",
        " \n",
        "print('Bagging Classifier:')\n",
        "print(confusion_matrix(bagging_y_classifier, y_test))\n",
        "\n",
        "print('Random Forest Classifier:')\n",
        "print(confusion_matrix(random_forest_y_classifier, y_test))\n",
        "\n",
        "print('Ada Boost Classifier:')\n",
        "print(confusion_matrix(ada_boost_y_classifier, y_test))\n",
        "\n",
        "print('GBM Classifier:')\n",
        "print(confusion_matrix(gbm_y_classifier, y_test))\n",
        "\n",
        "print('XGBoost Classifier:')\n",
        "print(confusion_matrix(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier:\n",
            "[[41  0]\n",
            " [ 3 36]]\n",
            "Decision Trees Classifier:\n",
            "[[42  1]\n",
            " [ 2 35]]\n",
            "SVN Classifier:\n",
            "[[37  3]\n",
            " [ 7 33]]\n",
            "KNN Classifier:\n",
            "[[40  1]\n",
            " [ 4 35]]\n",
            "Naive Bayes Classifier:\n",
            "[[39  0]\n",
            " [ 5 36]]\n",
            "Bagging Classifier:\n",
            "[[41  0]\n",
            " [ 3 36]]\n",
            "Random Forest Classifier:\n",
            "[[43  0]\n",
            " [ 1 36]]\n",
            "Ada Boost Classifier:\n",
            "[[43  0]\n",
            " [ 1 36]]\n",
            "GBM Classifier:\n",
            "[[42  0]\n",
            " [ 2 36]]\n",
            "XGBoost Classifier:\n",
            "[[43  0]\n",
            " [ 1 36]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification in respect to True Positives and True Negatives is very high and all models with Random Forest, Ada Boost and XGBoost models having only one false negative indicating the accuracy of our model"
      ],
      "metadata": {
        "id": "C4AN3nMWE3Bi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBJJqpvjp_Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7241fcff-c5fe-45f2-dbde-4725bd9269e5"
      },
      "source": [
        "# Classification Reports\n",
        "print(\"Logistic Regression Classifier\", classification_report(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", classification_report(decision_y_prediction, y_test))\n",
        "print(\"SVM Classifier\", classification_report(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", classification_report(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", classification_report(naive_y_prediction, y_test))\n",
        "print(\"Bagging Classifier\", classification_report(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", classification_report(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", classification_report(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", classification_report(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", classification_report(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        41\n",
            "           1       1.00      0.92      0.96        39\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.96      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "Decision Trees Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97        43\n",
            "           1       0.97      0.95      0.96        37\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.96      0.96      0.96        80\n",
            "weighted avg       0.96      0.96      0.96        80\n",
            "\n",
            "SVM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88        40\n",
            "           1       0.92      0.82      0.87        40\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.88      0.88      0.87        80\n",
            "weighted avg       0.88      0.88      0.87        80\n",
            "\n",
            "KNN Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94        41\n",
            "           1       0.97      0.90      0.93        39\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.94      0.94      0.94        80\n",
            "weighted avg       0.94      0.94      0.94        80\n",
            "\n",
            "Naive Bayes Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        39\n",
            "           1       1.00      0.88      0.94        41\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.94      0.94      0.94        80\n",
            "weighted avg       0.94      0.94      0.94        80\n",
            "\n",
            "Bagging Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        41\n",
            "           1       1.00      0.92      0.96        39\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.96      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "Random Forest Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        43\n",
            "           1       1.00      0.97      0.99        37\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "Ada Boost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        43\n",
            "           1       1.00      0.97      0.99        37\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "GBM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        42\n",
            "           1       1.00      0.95      0.97        38\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.98      0.97      0.97        80\n",
            "weighted avg       0.98      0.97      0.97        80\n",
            "\n",
            "XGBoost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        43\n",
            "           1       1.00      0.97      0.99        37\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: the percentage of texts that were assigned the correct label.\n",
        "\n",
        "Precision: the percentage of texts the classifier classified correctly out of the total number of texts it predicted for each label\n",
        "\n",
        "Recall: the percentage of texts the model predicted for each topic out of the total number of texts it should have predicted for that label.\n",
        "\n",
        "F1 Score: the average of both precision and recall."
      ],
      "metadata": {
        "id": "Z9KkVyNfDiGR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA28XDA03Q9-"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASVijr_e3WF2"
      },
      "source": [
        "Your findings and recommendations...\n",
        "\n",
        "Our best perfornming models are Random Forest, Ada Boost and XGBoots classifiers which gave us the highest accuracy of 98.8%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI23jTyh5XDU"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6HR28mq6mg5"
      },
      "source": [
        "### a) Did we have the right question?\n",
        "Yes we did\n",
        "\n",
        "\n",
        "### b) Did we have the right data?\n",
        "Yes\n",
        "\n",
        "### c) What can be done to improve the solution? \n",
        "We can use different vectorizing techniques, implement other machine learning models, perform hyperparameter tuning and sample a balanced dataset.\n"
      ]
    }
  ]
}